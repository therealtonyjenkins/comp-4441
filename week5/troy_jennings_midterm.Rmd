---
title: "Problem Set 5"
author: "Troy Jennings"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Introduction

As an application of the some of the properties of expected values, problems 1-7 step through a proof that the expected value of the random variable that defines sample variance is the population variance, given that the population variance is defined. 

For each of these questions, let $X_1,X_2,...X_n$ be independent, identically distributed random variables with defined mean $\mu$ and variance $\sigma^2$.

Question 8 gives examples of jointly distributed random variables that are independent and jointly distributed random variables that aren't independent.

Please complete the following tasks regarding the data in R. Please generate a solution document in R markdown and upload the .Rmd document and a rendered  .doc, .docx, or .pdf document.   Please turn in your work on Canvas. 

These questions were rendered in R markdown through RStudio (<https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf>, <http://rmarkdown.rstudio.com> ).

## Question 1 (5 points)

Let $X_1,X_2,...X_n$ be independent, identically distributed random variables with mean $\mu$ and variance $\sigma^2$, and define the random variable $\bar X$ by $\bar X=\frac{1}{n}\sum_{i=1}^nX_i$. Justify the equality $$E\left[\sum_{i=1}^n\left(X_i-\bar X\right)^2\right]=E\left[\sum_{i=1}^nX_i^2\right]-2E\left[\sum_{i=1}^n\bar XX_i\right]+E\left[\sum_{i=1}^n\bar X^2\right]$$



## Question 2 (5 points)

Let $X_1,X_2,...X_n$ be independent, identically distributed random variables with mean $\mu$ and variance $\sigma^2$.

In terms of $\mu$ and $\sigma^2$, what is the value of $E[X_i^2]$? Note that $Var[X_i]=E[X_i^2]-E[X_i]^2$, while $Var[X_i]=\sigma^2$ and $E[X_i]=\mu$. Please justify your answer.


Confirm numerically that your answer is correct for $X_i\sim gamma(shape=3,scale=2)$ which has mean equal to $6$ and variance equal to $12$. 

```{r}
f2<-function(x){x^2*dgamma(x,shape=3,scale=2)}
integrate(f2,0,Inf)$value


```

## Question 3 (5 points)

Assuming that $E[X_i^2]=\sigma^2+\mu^2$ for all $i$, what is $E\left[\sum_{i=1}^nX_i^2\right]$. Recall that $E\left[\sum_{i=1}^nY_i\right]=\sum_{i=1}^nE[Y_i]$ for any random variables $Y_i,Y_2...Y_n$ with defined means.


## Question 4 (5 points)

Define the random variable $\bar X$ by $\bar X=\frac{1}{n}\sum_{i=1}^nX_i$. What is the value of $E\left[\sum_{i=1}^n\bar X^2\right]$? Please justify your answer. 

  Recall that the mean of $\bar X$ equals $\mu$ and the variance equals $\frac{\sigma^2}{n}$. The fact that $E\left[\sum_{i=1}^nY_i\right]=\sum_{i=1}^nE[Y_i]$ mentioned above may also be useful. Further, $\bar X$ is constant with respect to the index $i$ in the sum.


## Question 5 (10 points)

Why is 
$$E\left[\sum_{i=1}^n\bar XX_i\right]=E\left[\bar X\sum_{i=1}^nX_i\right]=E\left[n\bar X^2\right]$$


## Question 6 (5 points)


Assuming that $E\left[\sum_{i=1}^nX_i^2\right]=n\left(\sigma^2+\mu^2\right)$, that $E\left[\sum_{i=1}^n\bar X^2\right]=n\left(\frac{\sigma^2}{n}+\mu^2\right)$, and that $E\left[\sum_{i=1}^n\bar XX_i\right]=E\left[n\bar X^2\right]=n\left(\frac{\sigma^2}{n}+\mu^2\right)$, please simplify $E\left[\sum_{i=1}^nX_i^2\right]-2E\left[\sum_{i=1}^n\bar XX_i\right]+E\left[\sum_{i=1}^n\bar X^2\right]$.


## Question 7 (5 points)

If $E\left[\sum_{i=1}^nX_i^2\right]-2E\left[\sum_{i=1}^n\bar XX_i\right]+E\left[\sum_{i=1}^n\bar X^2\right]=(n-1)\sigma^2$, what is the value of $E\left[\frac{1}{n-1}\sum_{i=1}^n\left(X_i-\bar X\right)^2\right]$?


## Question 8

*  Consider the probability space defined by $(S,M,P)$ where $S=\{a,b,c,d,e,f\}$, the set of events $M$ is the power set of $S$, and $P$ is defined by the density $f(s)=\frac{1}{6}$ for all $s\in S$. Let $X$ be the random variable on this probability space defined by $X(a)=X(b)=X(c)=1$ and $X(d)=X(e)=X(f)=0$. Define $Y$ by $Y(a)=Y(d)=2$, $Y(b)=Y(c)=Y(e)=Y(f)=3$. Are these random variables independent?


*  Consider the probability space defined by $(S,M,P)$ where $S=\{a,b,c,d,e,f\}$, the set of events $M$ is the power set of $S$, and $P$ is defined by the density $f(s)=\frac{1}{6}$ for all $s\in S$. Let $X$ be the random variable on this probability space defined by $X(a)=X(d)=X(e)=1$ and $X(b)=X(c)=X(f)=0$. Define $Y$ by $Y(a)=Y(d)=2$, $Y(b)=Y(c)=Y(e)=Y(f)=3$. Are these random variables independent?

## Question 9

Suppose $a$ is a sample from a random variable $A$ and $b$ is a sample from a random variable $B$ with variances $v$ and $w$ respectively. What weighted average $xa+(1-x)b$ with $x\in[0,1]$ minimizes the variance of $xa+(1-x)b$?

